{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from functions import fill_batch, make_dict, take_len\n",
    "from BiLSTM import BiLSTM\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "import pickle\n",
    "import generators as gens\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "train_txt = \"../data/ja_train.txt\" # \"../data/train.kaneko.txt\"\n",
    "# dev_txt = \"../data/dev.kaneko.txt\"\n",
    "test_txt =  \"../data/ja_valid.txt\" # \"../data/test.kaneko.txt\"\n",
    "load_model  = \"../ptmodel/ptBLSTM.model0\"\n",
    "vocab_dict = \"../ptmodel/BLSTMVocab.pkl\"\n",
    "\n",
    "vocab_size = take_len(train_txt)\n",
    "batch_size = 256\n",
    "embed_size = 300\n",
    "output_size = 2\n",
    "hidden_size = 200\n",
    "extra_hidden_size = 50\n",
    "epoch = 30\n",
    "\n",
    "def precision_recall_f(pres, tags, cons):\n",
    "    c_p = 0  # actual\n",
    "    correct_p = 0  # predicted\n",
    "    c_r = 0\n",
    "    correct_r = 0\n",
    "    _tags = np.array(tags, dtype=np.int64)\n",
    "    tags = Variable(torch.from_numpy(_tags).t())\n",
    "    if torch.cuda.is_available:\n",
    "        tags = tags.cuda()\n",
    "\n",
    "    for num, a in enumerate(zip(pres, tags)):\n",
    "        a = torch.tensor(a)\n",
    "        pre_l = [int(a[0].data[k]) for k in range(len(a[0].data)) if cons[num][k] == True]\n",
    "        tag_l = [int(a[1].data[n]) for n in range(len(a[1].data)) if cons[num][n] == True]\n",
    "        for a, b in zip(tag_l, pre_l):\n",
    "            if a == 1:\n",
    "                c_r += 1\n",
    "                if b == a:\n",
    "                    correct_r += 1\n",
    "            if b == 1:\n",
    "                c_p += 1\n",
    "                if b == a:\n",
    "                    correct_p += 1\n",
    "    return c_p, correct_p, c_r, correct_r\n",
    "\n",
    "def evaluate(model, word2vec):\n",
    "    c_p = 0\n",
    "    correct_p = 0\n",
    "    c_r = 0\n",
    "    correct_r = 0\n",
    "    m = model.copy()\n",
    "    gen1 = gens.word_list(dev_txt)\n",
    "    gen2 = gens.batch(gens.sortedparallel(gen1, embed_size*batch_size), batch_size)\n",
    "    batchs = [b for b in gen2]\n",
    "    for batch in batchs:\n",
    "        tag0 = batch[:]\n",
    "        tags = [a[:-1] for a in tag0]\n",
    "        batch = batch[1:]\n",
    "        batch = fill_batch(b[-1].split() for b in batch)\n",
    "        tags = fill_batch(tags, token=-1)\n",
    "        pres, cons = forward(batch, tags, m, word2id, mode=False)\n",
    "        a,b,c,d = precision_recall_f(pres, tags, cons)\n",
    "        c_p += a\n",
    "        correct_p += b\n",
    "        c_r += c\n",
    "        correct_r += d\n",
    "    try:\n",
    "        precision = correct_p / c_p\n",
    "        recall = correct_r / r\n",
    "        f_measure = (1 + 0.5**2)*precision*recall / (0.5**2*precision + recall)\n",
    "    except:\n",
    "        precision = 'nothing'\n",
    "        recall = 'nothing'\n",
    "        f_measure = 'nothing'\n",
    "    print('Precision:\\t{}'.format(precision))\n",
    "    print('Recall:\\t{}'.format(recall))\n",
    "    print('F-Value:\\t{}'.fotmat(f_measure))\n",
    "\n",
    "def forward(batchs, tags, model, word2id, mode):\n",
    "    argmax_pres = []\n",
    "    cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    x = Variable(torch.LongTensor([[word2id[word] if word in word2id else word2id['<unk>'] for word in sen] for sen in batchs])).t()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "\n",
    "    pres = model(x)\n",
    "    for pre in pres:\n",
    "        argmax_pres.append([int(torch.argmax(ele)) for ele in pre])\n",
    "    condition = x.data != -1\n",
    "    if mode:  # are we calculating the loss??\n",
    "        accum_loss = Variable(torch.zeros(1))  # initialize the loss count to zero\n",
    "        _tags = np.array(tags, dtype=np.int64)\n",
    "        tags = Variable(torch.from_numpy(_tags)).t() # (padded_sentence_length, batch_size)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            accum_loss = accum_loss.cuda()\n",
    "            tags = tags.cuda()\n",
    "\n",
    "        for tag, pre in zip(tags, pres):\n",
    "            accum_loss += cross_entropy_loss(pre, tag)\n",
    "\n",
    "        return accum_loss, argmax_pres, condition\n",
    "\n",
    "    return argmax_pres, condition\n",
    "\n",
    "\n",
    "def evaluate(model, word2id):\n",
    "    c_p = 0\n",
    "    correct_p = 0\n",
    "    c_r = 0\n",
    "    correct_r = 0\n",
    "\n",
    "    gen1 = gens.word_list(test_txt)\n",
    "    gen2 = gens.batch(gens.sorted_parallel(gen1, embed_size * batch_size), batch_size)\n",
    "    batchs = [b for b in gen2]\n",
    "    for batch in batchs:\n",
    "        tag0 = batch[:]\n",
    "        tags = [a[:-1] for a in tag0]\n",
    "        batch = fill_batch([b[-1].split() for b in batch])\n",
    "        tags = fill_batch(tags, token=-1)\n",
    "        pres, cons = forward(batch, tags, model, word2id, mode=False)\n",
    "        a, b, c, d = precision_recall_f(pres, tags, cons)\n",
    "        c_p += a\n",
    "        correct_p += b\n",
    "        c_r += c\n",
    "        correct_r += d\n",
    "    try:\n",
    "        precision = correct_p / c_p\n",
    "        recall = correct_r / c_r\n",
    "        f_measure = (1 + 0.5 ** 2) * precision * recall / (0.5 ** 2 * precision + recall)\n",
    "        print('Precision:\\t{}'.format(precision))\n",
    "        print('Recall:\\t{}'.format(recall))\n",
    "        print('F-value\\t{}'.format(f_measure))\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f_measure = 0\n",
    "        print('Precision:\\tnothing')\n",
    "        print('Recall:\\tnothing')\n",
    "        print('F-value\\tnothing')\n",
    "    return precision, recall, f_measure\n",
    "\n",
    "\n",
    "def train():\n",
    "    id2word = {}\n",
    "    word2id = {}\n",
    "    word_freq = collections.defaultdict(lambda: 0)\n",
    "    id2word[0] = \"<unk>\"\n",
    "    word2id[\"<unk>\"] = 0\n",
    "    id2word[1] = \"<s>\"\n",
    "    word2id[\"<s>\"] = 1\n",
    "    id2word[2] = \"</s>\"\n",
    "    word2id[\"</s>\"] = 2\n",
    "\n",
    "    word2id, id2word, word_list, word_freq = make_dict(train_txt, word2id, id2word, word_freq)\n",
    "    model = BiLSTM(vocab_size, embed_size, hidden_size, output_size, extra_hidden_size)\n",
    "    model.initialize_embed('../data/embedding.txt', word2id)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for i in range(1, epoch + 1):\n",
    "        print(\"\\nepoch {}\".format(i))\n",
    "        total_loss = 0\n",
    "        gen1 = gens.word_list(train_txt)\n",
    "        gen2 = gens.batch(gens.sorted_parallel(gen1, embed_size * batch_size), batch_size)\n",
    "        batchs = [b for b in gen2]\n",
    "        bl = list(range(len(batchs)))\n",
    "        random.shuffle(bl)\n",
    "        for n, j in enumerate(bl):\n",
    "            tag0 = batchs[j][:]\n",
    "            tags = [[int(c) for c in a[:-1]] for a in tag0]\n",
    "            batch = fill_batch([b[-1].split() for b in batchs[j]])\n",
    "            tags = fill_batch(tags, token=0)\n",
    "            accum_loss, pres, cons = forward(batch, tags, model, word2id, mode=True)\n",
    "            accum_loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += accum_loss.data[0]\n",
    "        print(\"total_loss {}\".format(total_loss))\n",
    "        evaluate(model, word2id)\n",
    "        torch.save(model.state_dict(), \"{}{}\".format(load_model, i))\n",
    "\n",
    "    torch.save(model.state_dict(), load_model)\n",
    "    with open(vocab_dict, mode='wb') as f:\n",
    "        pickle.dump(word2id, f)\n",
    "\n",
    "def test():\n",
    "    res = []\n",
    "    word2id = pickle.load(open(vocab_dict, 'rb'))\n",
    "    model = BiLSTM(vocab_size, embed_size, hidden_size, output_size, extra_hidden_size)\n",
    "    model.load_state_dict(torch.load(load_model))\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    for i in range(1, epoch + 1):\n",
    "        print(\"\\nepoch {}\".format(i))\n",
    "        total_loss = 0\n",
    "        gen1 = gens.word_list(test_txt)\n",
    "        gen2 = gens.batch(gens.sorted_parallel(gen1, embed_size*batch_size), batch_size)\n",
    "        batchs = [b for b in gen2]\n",
    "        bl = list(range(len(batchs)))\n",
    "        random.shuffle(bl)\n",
    "        for n, j in enumerate(bl):\n",
    "            tag0 = batchs[j][:]\n",
    "            tags = [[int(c) for c in a[:-1]] for a in tag0]\n",
    "            batch = fill_batch([b[-1].split() for b in batchs[j]])\n",
    "            tags = fill_batch(tags, token=0)\n",
    "            accum_loss, pres, cons = forward(batch, tags, model, word2id, mode=True)\n",
    "            total_loss += accum_loss.data[0]\n",
    "            pres = np.array(pres, dtype=np.int64).T\n",
    "            for pre, text in zip(pres, batch):\n",
    "                pre = [str(p) for p in pre]\n",
    "                res.append(' '.join(pre) + '\\t' + ' '.join(text))\n",
    "        print(\"total_loss {}\".format(total_loss))\n",
    "        with open('./save1.txt', 'w') as f:\n",
    "            f.write('\\n'.join(res))\n",
    "        evaluate(model, word2id) # F値を出したい場合はこちら\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1\n",
      "total_loss 13.935344696044922\n",
      "Precision:\t0.6866840731070496\n",
      "Recall:\t0.9894657637321295\n",
      "F-value\t0.731449549449327\n",
      "\n",
      "epoch 2\n",
      "total_loss 13.983169555664062\n",
      "Precision:\t0.6866840731070496\n",
      "Recall:\t0.9894657637321295\n",
      "F-value\t0.731449549449327\n",
      "\n",
      "epoch 3\n",
      "total_loss 13.939706802368164\n",
      "Precision:\t0.6852527357998958\n",
      "Recall:\t0.9894657637321295\n",
      "F-value\t0.7301499167129374\n",
      "\n",
      "epoch 4\n",
      "total_loss 13.988617897033691\n",
      "Precision:\t0.6856100104275287\n",
      "Recall:\t0.9894657637321295\n",
      "F-value\t0.7304743917342519\n",
      "\n",
      "epoch 5\n",
      "total_loss 13.922900199890137\n",
      "Precision:\t0.6863256784968684\n",
      "Recall:\t0.9894657637321295\n",
      "F-value\t0.7311242077171134\n",
      "\n",
      "epoch 6\n",
      "total_loss 14.009521484375\n",
      "Precision:\t0.6868475991649269\n",
      "Recall:\t0.9902182091798345\n",
      "F-value\t0.7316801957077727\n",
      "\n",
      "epoch 7\n",
      "total_loss 14.069356918334961\n",
      "Precision:\t0.6857738405419489\n",
      "Recall:\t0.9902182091798345\n",
      "F-value\t0.7307051637978901\n",
      "\n",
      "epoch 8\n",
      "total_loss 14.114437103271484\n",
      "Precision:\t0.6854460093896714\n",
      "Recall:\t0.9887133182844243\n",
      "F-value\t0.7302434144714907\n",
      "\n",
      "epoch 9\n",
      "total_loss 13.94921588897705\n",
      "Precision:\t0.68580375782881\n",
      "Recall:\t0.9887133182844243\n",
      "F-value\t0.7305682197264538\n",
      "\n",
      "epoch 10\n",
      "total_loss 13.862281799316406\n",
      "Precision:\t0.6875981161695447\n",
      "Recall:\t0.9887133182844243\n",
      "F-value\t0.7321965897693079\n",
      "\n",
      "epoch 11\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
